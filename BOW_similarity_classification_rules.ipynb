{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-w0wBRCQU99y"
   },
   "source": [
    "#Rule similarity based on Bag of Word representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import seaborn as sns;\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "#define rulesets path and destination path \n",
    "filepath=\"\"\n",
    "rulepath=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1790,
     "status": "ok",
     "timestamp": 1635420086541,
     "user": {
      "displayName": "Melissa Ferretti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg6YggI57po9T0w2iVlNdS1e3fG1TfOURMiLOPZMQ=s64",
      "userId": "02788396767801992711"
     },
     "user_tz": -120
    },
    "id": "3TJ_Xr7PVnIy"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "#real dataset\n",
    "ruleset_r=pd.read_csv(rulepath+\"ruleset1.csv\", header=None) \n",
    "ruleset_r['n'] = pd.Series( ruleset_r.index+1).astype(\"string\")\n",
    "print(ruleset_r.iloc[:,0])\n",
    "print(ruleset_r.iloc[:,1])\n",
    "print(ruleset_r.iloc[:,2])\n",
    "ruleset_r['Rule'] = ruleset_r.apply(lambda x: x[0][x[0].find('IF')+3:x[0].find('THEN')-1], axis=1)\n",
    "ruleset_r['Covering'] = ruleset_r.apply(lambda x: x[1][x[1].find(':')+2:], axis=1)\n",
    "ruleset_r['Error'] = ruleset_r.apply(lambda x: x[2][x[2].find(':')+2:], axis=1)\n",
    "ruleset_r['Class'] = ruleset_r.apply(lambda x: x[0][x[0].find('\"')+1:x[0].find('\"')+2], axis=1)\n",
    "ruleset_r.drop(ruleset_r.iloc[:,0:3] , axis=1, inplace=True)\n",
    "ruleset_r['Set']='real'\n",
    "print(ruleset_r)\n",
    "\n",
    "#synthetic dataset\n",
    "ruleset_s=pd.read_csv(rulepath+\"ruleset2.csv\", header=None) \n",
    "ruleset_s['n'] = pd.Series( ruleset_s.index+1)\n",
    "ruleset_s['Rule'] = ruleset_s.apply(lambda x: x[0][x[0].find('IF')+3:x[0].find('THEN')-1], axis=1)\n",
    "ruleset_s['Covering'] = ruleset_s.apply(lambda x: x[1][x[1].find(':')+2:], axis=1)\n",
    "ruleset_s['Error'] = ruleset_s.apply(lambda x: x[2][x[2].find(':')+2:], axis=1)\n",
    "ruleset_s['Class'] = ruleset_s.apply(lambda x: x[0][x[0].find('\"')+1:x[0].find('\"')+2], axis=1)\n",
    "ruleset_s.drop(ruleset_s.iloc[:,0:3] , axis=1, inplace=True)\n",
    "ruleset_s['Set']='synth'\n",
    "print(ruleset_s)\n",
    "\n",
    "#concatenate real and synthetic rulesets and select rules with covering above 15%\n",
    "ruleset = pd.concat([ruleset_r, ruleset_s], ignore_index=True)\n",
    "ruleset=ruleset[ruleset[\"Covering\"].astype('float')>0.15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_litteral(classe):\n",
    "    if classe == '1':\n",
    "        return 'HL'\n",
    "    else:\n",
    "        return 'noHL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1635420105972,
     "user": {
      "displayName": "Melissa Ferretti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg6YggI57po9T0w2iVlNdS1e3fG1TfOURMiLOPZMQ=s64",
      "userId": "02788396767801992711"
     },
     "user_tz": -120
    },
    "id": "gApx84m6EnEg",
    "outputId": "fdb78128-cc43-4010-96b9-35099970db4d"
   },
   "outputs": [],
   "source": [
    "ruleset['Class'] = ruleset['Class'].apply(convert_litteral)\n",
    "ruleset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1LyI0aubDNw"
   },
   "outputs": [],
   "source": [
    "ruleset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1635420128073,
     "user": {
      "displayName": "Melissa Ferretti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg6YggI57po9T0w2iVlNdS1e3fG1TfOURMiLOPZMQ=s64",
      "userId": "02788396767801992711"
     },
     "user_tz": -120
    },
    "id": "O2J23zndbklA"
   },
   "outputs": [],
   "source": [
    "#extract feature and sign of each condition\n",
    "from collections import Counter\n",
    "words = []\n",
    "unilateral_conditions=[]\n",
    "for index, value in ruleset.loc[:,'Rule'].items():\n",
    "    for r in value.split(' AND '): #split each rules in r conditions, based on the splitting variable AND\n",
    "        if r.count('<')==2:  #if the condition is defined by intervals (n1<x<n2), in order to split them into two unilateral conditions\n",
    "            second=r[r.find('<')+2:] # second part of the interval x<n2\n",
    "            words.append(second[:second.find('<')+2].replace(\" \", \"\"))  # extract feature + sign (n1<) of the second part of the interval and removes the cut-off value\n",
    "            feat=second[:second.find('<')] #extract the feature name\n",
    "            if r.find('<')+1== '=': \n",
    "                first=feat+'>= '+r[:r.find('<')] # first condition n1<=x-> x>=n1\n",
    "            else:\n",
    "                first=feat+'> '+r[:r.find('<')] # first condition n1<x-> x>n1\n",
    "                \n",
    "            words.append(first[:first.find('>')+2].replace(\" \", \"\"))  # extract feature + sign (n1>= or n1>) of the first part of the interval and removes the cut-off value  \n",
    "            #split and save intervals as 2 unilateral conditions\n",
    "            unilateral_conditions.append(second);\n",
    "            unilateral_conditions.append(first);\n",
    "        elif r.find('>')>0: # else if the condition is unilateral, in the form x>\n",
    "            unilateral_conditions.append(r);\n",
    "            words.append(r[:r.find('>')+2].replace(\" \", \"\"))            \n",
    "        else: # else if the condition is unilateral, in the form x<\n",
    "            unilateral_conditions.append(r);\n",
    "            words.append(r[:r.find('<')+2].replace(\" \", \"\"))\n",
    "print(words)\n",
    "counter = Counter(words) #vector that store the list of words (unique) and their occurrence\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSTNfKGSsCgW"
   },
   "outputs": [],
   "source": [
    "for i in counter: #for each word in the list creates three new colums in the ruleset: one for presence/absence of the word in the rule, one for the cut-off value and one for the normalized cut-off value \n",
    "    ruleset.loc[:,i]= 0\n",
    "    ruleset[i+'Value']=0.0\n",
    "    ruleset[i+'ValueNorm']=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 321,
     "status": "ok",
     "timestamp": 1635420148839,
     "user": {
      "displayName": "Melissa Ferretti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg6YggI57po9T0w2iVlNdS1e3fG1TfOURMiLOPZMQ=s64",
      "userId": "02788396767801992711"
     },
     "user_tz": -120
    },
    "id": "EcXNUQi-4R3K"
   },
   "outputs": [],
   "source": [
    "#for each word fill the correspondent column with 1 is the word is present in the rule, in that case, fill the value column with the correspondent cut-off value\n",
    "for c in counter:\n",
    "    for index, value in ruleset.loc[:,'Rule'].items():\n",
    "        \n",
    "        for r in value.split(' AND '): #for each single condition\n",
    "            if r.count('<')==2:  #search for conditions defined by intervals (n1<x<n2)\n",
    "                second=r[r.find('<')+2:] \n",
    "                feat=second[:second.find('<')] \n",
    "                if r.find('<')+1== '=': \n",
    "                    first=feat+'>= '+r[:r.find('<')] #first condition n1<=x-> x>=n1\n",
    "                else:\n",
    "                    first=feat+'> '+r[:r.find('<')] #first condition n1<x-> x>n1\n",
    "                if first[:first.find('>')+2].replace(\" \", \"\") == c:\n",
    "                    ruleset.loc[index, c] = 1 \n",
    "                    ruleset.loc[index, c+'Value'] = float(first.split('>')[1].strip())    \n",
    "                if second[:second.find('<')+2].replace(\" \", \"\") == c:\n",
    "                    ruleset.loc[index, c] = 1\n",
    "                    if second.find('='):\n",
    "                        ruleset.loc[index, c+'Value'] = float(second.split('<=')[1].strip()) \n",
    "                    else:   \n",
    "                        ruleset.loc[index, c+'Value'] = float(second.split('<')[1].strip())           \n",
    "            elif r[:r.find('>')+2].replace(\" \", \"\") == c:\n",
    "                ruleset.loc[index, c] = 1\n",
    "                ruleset.loc[index, c+'Value'] = float(r.split('>')[1].strip())\n",
    "            elif r[:r.find('<')+2].replace(\" \", \"\") == c:\n",
    "                ruleset.loc[index, c] = 1\n",
    "                ruleset.loc[index, c+'Value'] = float(r.split('<=')[1].strip())\n",
    "print(ruleset)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectors of maximum and minimum (normative) values for each feature that will be hardly never present in a classification rule\n",
    "feature_names= ['srt', 'Age', 'trials', 'correct', '%correct', 'avg_reaction_time', 'total_test_time', 'volume']\n",
    "minVet=[-25,0,20,15,0,0.5,100,1]\n",
    "maxVet=[25,99,150,125,100,10,180,0.9] \n",
    "for c in counter: #normalize each column value between 0 and 1 by considering minimum and maximum possible values (hardly never achieved)  \n",
    "    for feat in feature_names: #for each feature\n",
    "        if c.count(feat)==1: \n",
    "            maxFeat=maxVet[feature_names.index(feat)]\n",
    "            minFeat=minVet[feature_names.index(feat)]\n",
    "    valueColIndex=ruleset.columns.get_loc(c)+1\n",
    "    for rowIndex, value in ruleset.iloc[:,valueColIndex].items():\n",
    "        if ruleset.iloc[rowIndex, valueColIndex]==0: #when the word column is zero\n",
    "            ruleset.iloc[rowIndex, valueColIndex+1] =0 #also the value column is 0 (as the minimum is never present in a classification rule, we have value 0 only if the word is not present)\n",
    "        else:\n",
    "            ruleset.iloc[rowIndex, valueColIndex+1] = (ruleset.iloc[rowIndex, valueColIndex]-minFeat)/(maxFeat-minFeat) #normalize between min and max\n",
    "for c in counter: #reset the cut-off value column and keeps only the normalized values\n",
    "    del ruleset[c+'Value'] \n",
    "print(ruleset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 722,
     "status": "ok",
     "timestamp": 1635420181715,
     "user": {
      "displayName": "Melissa Ferretti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg6YggI57po9T0w2iVlNdS1e3fG1TfOURMiLOPZMQ=s64",
      "userId": "02788396767801992711"
     },
     "user_tz": -120
    },
    "id": "ob_GM85weU8M"
   },
   "outputs": [],
   "source": [
    "# divide the rules by class as only rules characterizing the same output class will be compared\n",
    "ruleset_HL=ruleset[ruleset['Class']=='HL']\n",
    "ruleset_noHL=ruleset[ruleset['Class']=='noHL']\n",
    "print(ruleset_HL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 361,
     "status": "ok",
     "timestamp": 1635420704660,
     "user": {
      "displayName": "Melissa Ferretti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg6YggI57po9T0w2iVlNdS1e3fG1TfOURMiLOPZMQ=s64",
      "userId": "02788396767801992711"
     },
     "user_tz": -120
    },
    "id": "ZiE8g8Ie3ZsB"
   },
   "outputs": [],
   "source": [
    "#convert the columns of the BOW matrix into arrays to compute cosine similarity\n",
    "matrix_noHL = ruleset_noHL.iloc[:,6:ruleset_noHL.shape[1]].to_numpy()\n",
    "matrix_HL = ruleset_HL.iloc[:,6:ruleset_HL.shape[1]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 369,
     "status": "ok",
     "timestamp": 1635420708041,
     "user": {
      "displayName": "Melissa Ferretti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg6YggI57po9T0w2iVlNdS1e3fG1TfOURMiLOPZMQ=s64",
      "userId": "02788396767801992711"
     },
     "user_tz": -120
    },
    "id": "bde2aQDs90cy"
   },
   "outputs": [],
   "source": [
    "#calculate cosine similarity of the BOW matrixes, one for each output class\n",
    "cos_sim_noHL = cosine_similarity (matrix_noHL, matrix_noHL)\n",
    "cos_sim_HL = cosine_similarity (matrix_HL, matrix_HL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foHL78v6_o9I"
   },
   "outputs": [],
   "source": [
    "# Matrixes of cosine similarity between rules, max similarity=1 (same rule) \n",
    "#the cell in position i,j cointains the similarity coefficient between rule i and rule j\n",
    "similarity_matrix_noHL = pd.DataFrame(cos_sim_noHL,\n",
    "                   index = ruleset_noHL['Set'] +' - Rule: ' +  ruleset_noHL['n'].astype(\"string\"),\n",
    "                   #index=phrases,\n",
    "                   columns = ruleset_noHL['Set'] + ' - Rule: ' + ruleset_noHL['n'].astype(\"string\"))\n",
    "                   #columns=phrases)\n",
    "similarity_matrix_HL = pd.DataFrame(cos_sim_HL,\n",
    "                   index = ruleset_HL['Set'] +' - Rule: ' + ruleset_HL['n'].astype(\"string\"),\n",
    "                   #index=phrases,\n",
    "                   columns = ruleset_HL['Set'] + ' - Rule: '  + ruleset_HL['n'].astype(\"string\"))\n",
    "                   #columns=phrases)\n",
    "\n",
    "print(similarity_matrix_noHL)\n",
    "print(similarity_matrix_HL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust rule similarity by considering covering differences between rules: max similarity=1 (same rule structure and covering) \n",
    "# no HL\n",
    "ruleset_noHL.reset_index(drop=True, inplace=True)\n",
    "cov_as_float=ruleset_noHL['Covering'].astype('float') #vector of covering values for rules describing the no HL class\n",
    "\n",
    "for i in range (similarity_matrix_noHL.shape[1]):    \n",
    "    for j in range (similarity_matrix_noHL.shape[1]):       \n",
    "        if(similarity_matrix_noHL.iat[i,j]!=0): #if the rule similarity of a couple of rule i,j is not zero\n",
    "            tmp=1-(abs(cov_as_float[i]-cov_as_float[j])) \n",
    "            similarity_matrix_noHL.iat[i,j]= similarity_matrix_noHL.iat[i,j]*tmp #adjust rule similarity coefficient between rule i and j\n",
    "            \n",
    "\n",
    "#%matplotlib notebook \n",
    "sns.set_theme()\n",
    "font = {'family' : 'normal','weight' : 'bold','size'   : 10}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "#PLOT THE RULE SIMILARITY MATRIX FOR NO HL RULES\n",
    "mask = np.zeros_like(similarity_matrix_noHL)\n",
    "mask[np.triu_indices_from(mask)] = True #plots only lower triangular matrix (the matrix is simmetric)\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(figsize=(20, 15))\n",
    "    ax = sns.heatmap(similarity_matrix_noHL, mask=mask, square=True,cbar_kws={'label': 'Rule similarity coef'},vmin=0, vmax=1,annot=True)\n",
    "    ax.set_title('Rule similarity matrix adjusted by covering (no HL rules)')\n",
    "\n",
    "# HL\n",
    "ruleset_HL.reset_index(drop=True, inplace=True)\n",
    "cov_as_float=ruleset_HL['Covering'].astype('float') #vector of covering values for rules describing the HL class\n",
    "for i in range (similarity_matrix_HL.shape[1]):    \n",
    "    for j in range (similarity_matrix_HL.shape[1]):       \n",
    "        if(similarity_matrix_HL.iat[i,j]!=0):\n",
    "            tmp=1-(abs(cov_as_float[i]-cov_as_float[j]))\n",
    "            similarity_matrix_HL.iat[i,j]= similarity_matrix_HL.iat[i,j]*tmp #adjust rule similarity coefficient \n",
    "            \n",
    "#PLOT THE RULE SIMILARITY MATRIX FOR NO HL RULES\n",
    "mask = np.zeros_like(similarity_matrix_HL)\n",
    "mask[np.triu_indices_from(mask)] = True #plots only lower triangular matrix (the matrix is simmetric)\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(figsize=(20, 15))\n",
    "    ax = sns.heatmap(similarity_matrix_HL, mask=mask, square=True,cbar_kws={'label': 'Rule similarity coef'},vmin=0, vmax=1,annot=True)\n",
    "    ax.set_title('Rule similarity matrix adjusted by covering (HL rules)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 441,
     "status": "ok",
     "timestamp": 1635420569013,
     "user": {
      "displayName": "Melissa Ferretti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg6YggI57po9T0w2iVlNdS1e3fG1TfOURMiLOPZMQ=s64",
      "userId": "02788396767801992711"
     },
     "user_tz": -120
    },
    "id": "Xunlf1omCVU4"
   },
   "outputs": [],
   "source": [
    "#save to Excel\n",
    "similarity_matrix_HL.to_excel(filepath+'Rule_similarity.xlsx', sheet_name='HL',index=True)\n",
    "similarity_matrix_noHL.to_excel(filepath+'Rule_similarity.xlsx', sheet_name='noHL',index=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOk/Thv2Fl4qMlpLsmTm5NO",
   "collapsed_sections": [
    "OaelgBBHCIO3",
    "cm5oNWKdgJl4"
   ],
   "name": "DistanzaRegole29_10.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
